{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "baking-remove",
   "metadata": {},
   "source": [
    "# E2-13. 유방암 여부 진단 프로젝트"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "duplicate-remark",
   "metadata": {},
   "source": [
    "## (1) 필요한 모듈 import하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "written-corpus",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix, plot_confusion_matrix, recall_score, precision_score, f1_score, accuracy_score\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "usual-quality",
   "metadata": {},
   "source": [
    "## (2) 데이터 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "artificial-logan",
   "metadata": {},
   "outputs": [],
   "source": [
    "cancer = load_breast_cancer()\n",
    "\n",
    "X = cancer['data']\n",
    "y = cancer['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "collect-gateway",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((569, 30), (569,))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "alternate-kansas",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names', 'filename'])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancer.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "protected-alert",
   "metadata": {},
   "source": [
    "## (3) 데이터 이해하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "focal-times",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _breast_cancer_dataset:\n",
      "\n",
      "Breast cancer wisconsin (diagnostic) dataset\n",
      "--------------------------------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 569\n",
      "\n",
      "    :Number of Attributes: 30 numeric, predictive attributes and the class\n",
      "\n",
      "    :Attribute Information:\n",
      "        - radius (mean of distances from center to points on the perimeter)\n",
      "        - texture (standard deviation of gray-scale values)\n",
      "        - perimeter\n",
      "        - area\n",
      "        - smoothness (local variation in radius lengths)\n",
      "        - compactness (perimeter^2 / area - 1.0)\n",
      "        - concavity (severity of concave portions of the contour)\n",
      "        - concave points (number of concave portions of the contour)\n",
      "        - symmetry\n",
      "        - fractal dimension (\"coastline approximation\" - 1)\n",
      "\n",
      "        The mean, standard error, and \"worst\" or largest (mean of the three\n",
      "        worst/largest values) of these features were computed for each image,\n",
      "        resulting in 30 features.  For instance, field 0 is Mean Radius, field\n",
      "        10 is Radius SE, field 20 is Worst Radius.\n",
      "\n",
      "        - class:\n",
      "                - WDBC-Malignant\n",
      "                - WDBC-Benign\n",
      "\n",
      "    :Summary Statistics:\n",
      "\n",
      "    ===================================== ====== ======\n",
      "                                           Min    Max\n",
      "    ===================================== ====== ======\n",
      "    radius (mean):                        6.981  28.11\n",
      "    texture (mean):                       9.71   39.28\n",
      "    perimeter (mean):                     43.79  188.5\n",
      "    area (mean):                          143.5  2501.0\n",
      "    smoothness (mean):                    0.053  0.163\n",
      "    compactness (mean):                   0.019  0.345\n",
      "    concavity (mean):                     0.0    0.427\n",
      "    concave points (mean):                0.0    0.201\n",
      "    symmetry (mean):                      0.106  0.304\n",
      "    fractal dimension (mean):             0.05   0.097\n",
      "    radius (standard error):              0.112  2.873\n",
      "    texture (standard error):             0.36   4.885\n",
      "    perimeter (standard error):           0.757  21.98\n",
      "    area (standard error):                6.802  542.2\n",
      "    smoothness (standard error):          0.002  0.031\n",
      "    compactness (standard error):         0.002  0.135\n",
      "    concavity (standard error):           0.0    0.396\n",
      "    concave points (standard error):      0.0    0.053\n",
      "    symmetry (standard error):            0.008  0.079\n",
      "    fractal dimension (standard error):   0.001  0.03\n",
      "    radius (worst):                       7.93   36.04\n",
      "    texture (worst):                      12.02  49.54\n",
      "    perimeter (worst):                    50.41  251.2\n",
      "    area (worst):                         185.2  4254.0\n",
      "    smoothness (worst):                   0.071  0.223\n",
      "    compactness (worst):                  0.027  1.058\n",
      "    concavity (worst):                    0.0    1.252\n",
      "    concave points (worst):               0.0    0.291\n",
      "    symmetry (worst):                     0.156  0.664\n",
      "    fractal dimension (worst):            0.055  0.208\n",
      "    ===================================== ====== ======\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "\n",
      "    :Class Distribution: 212 - Malignant, 357 - Benign\n",
      "\n",
      "    :Creator:  Dr. William H. Wolberg, W. Nick Street, Olvi L. Mangasarian\n",
      "\n",
      "    :Donor: Nick Street\n",
      "\n",
      "    :Date: November, 1995\n",
      "\n",
      "This is a copy of UCI ML Breast Cancer Wisconsin (Diagnostic) datasets.\n",
      "https://goo.gl/U2Uwz2\n",
      "\n",
      "Features are computed from a digitized image of a fine needle\n",
      "aspirate (FNA) of a breast mass.  They describe\n",
      "characteristics of the cell nuclei present in the image.\n",
      "\n",
      "Separating plane described above was obtained using\n",
      "Multisurface Method-Tree (MSM-T) [K. P. Bennett, \"Decision Tree\n",
      "Construction Via Linear Programming.\" Proceedings of the 4th\n",
      "Midwest Artificial Intelligence and Cognitive Science Society,\n",
      "pp. 97-101, 1992], a classification method which uses linear\n",
      "programming to construct a decision tree.  Relevant features\n",
      "were selected using an exhaustive search in the space of 1-4\n",
      "features and 1-3 separating planes.\n",
      "\n",
      "The actual linear program used to obtain the separating plane\n",
      "in the 3-dimensional space is that described in:\n",
      "[K. P. Bennett and O. L. Mangasarian: \"Robust Linear\n",
      "Programming Discrimination of Two Linearly Inseparable Sets\",\n",
      "Optimization Methods and Software 1, 1992, 23-34].\n",
      "\n",
      "This database is also available through the UW CS ftp server:\n",
      "\n",
      "ftp ftp.cs.wisc.edu\n",
      "cd math-prog/cpo-dataset/machine-learn/WDBC/\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "   - W.N. Street, W.H. Wolberg and O.L. Mangasarian. Nuclear feature extraction \n",
      "     for breast tumor diagnosis. IS&T/SPIE 1993 International Symposium on \n",
      "     Electronic Imaging: Science and Technology, volume 1905, pages 861-870,\n",
      "     San Jose, CA, 1993.\n",
      "   - O.L. Mangasarian, W.N. Street and W.H. Wolberg. Breast cancer diagnosis and \n",
      "     prognosis via linear programming. Operations Research, 43(4), pages 570-577, \n",
      "     July-August 1995.\n",
      "   - W.H. Wolberg, W.N. Street, and O.L. Mangasarian. Machine learning techniques\n",
      "     to diagnose breast cancer from fine-needle aspirates. Cancer Letters 77 (1994) \n",
      "     163-171.\n"
     ]
    }
   ],
   "source": [
    "print(cancer.DESCR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "naughty-chick",
   "metadata": {},
   "source": [
    "### Feature Data 지정하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "current-bridges",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569, 30)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = cancer.data\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stopped-subscriber",
   "metadata": {},
   "source": [
    "### Label Data 지정하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "grateful-carnival",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569,)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = cancer.target\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "generous-valuation",
   "metadata": {},
   "source": [
    "### Target Names 출력해 보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "rising-product",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['malignant', 'benign'], dtype='<U9')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancer.target_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "falling-creativity",
   "metadata": {},
   "source": [
    "### Feature Names 출력해 보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "conventional-package",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['mean radius', 'mean texture', 'mean perimeter', 'mean area',\n",
       "       'mean smoothness', 'mean compactness', 'mean concavity',\n",
       "       'mean concave points', 'mean symmetry', 'mean fractal dimension',\n",
       "       'radius error', 'texture error', 'perimeter error', 'area error',\n",
       "       'smoothness error', 'compactness error', 'concavity error',\n",
       "       'concave points error', 'symmetry error',\n",
       "       'fractal dimension error', 'worst radius', 'worst texture',\n",
       "       'worst perimeter', 'worst area', 'worst smoothness',\n",
       "       'worst compactness', 'worst concavity', 'worst concave points',\n",
       "       'worst symmetry', 'worst fractal dimension'], dtype='<U23')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancer.feature_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wound-reduction",
   "metadata": {},
   "source": [
    "### 데이터 Describe 해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "contrary-january",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst radius</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>25.380</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.16220</td>\n",
       "      <td>0.66560</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>24.990</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.12380</td>\n",
       "      <td>0.18660</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>23.570</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.14440</td>\n",
       "      <td>0.42450</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>14.910</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.20980</td>\n",
       "      <td>0.86630</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>22.540</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.13740</td>\n",
       "      <td>0.20500</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>21.56</td>\n",
       "      <td>22.39</td>\n",
       "      <td>142.00</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>0.11100</td>\n",
       "      <td>0.11590</td>\n",
       "      <td>0.24390</td>\n",
       "      <td>0.13890</td>\n",
       "      <td>0.1726</td>\n",
       "      <td>0.05623</td>\n",
       "      <td>...</td>\n",
       "      <td>25.450</td>\n",
       "      <td>26.40</td>\n",
       "      <td>166.10</td>\n",
       "      <td>2027.0</td>\n",
       "      <td>0.14100</td>\n",
       "      <td>0.21130</td>\n",
       "      <td>0.4107</td>\n",
       "      <td>0.2216</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.07115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>20.13</td>\n",
       "      <td>28.25</td>\n",
       "      <td>131.20</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>0.09780</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>0.14400</td>\n",
       "      <td>0.09791</td>\n",
       "      <td>0.1752</td>\n",
       "      <td>0.05533</td>\n",
       "      <td>...</td>\n",
       "      <td>23.690</td>\n",
       "      <td>38.25</td>\n",
       "      <td>155.00</td>\n",
       "      <td>1731.0</td>\n",
       "      <td>0.11660</td>\n",
       "      <td>0.19220</td>\n",
       "      <td>0.3215</td>\n",
       "      <td>0.1628</td>\n",
       "      <td>0.2572</td>\n",
       "      <td>0.06637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>16.60</td>\n",
       "      <td>28.08</td>\n",
       "      <td>108.30</td>\n",
       "      <td>858.1</td>\n",
       "      <td>0.08455</td>\n",
       "      <td>0.10230</td>\n",
       "      <td>0.09251</td>\n",
       "      <td>0.05302</td>\n",
       "      <td>0.1590</td>\n",
       "      <td>0.05648</td>\n",
       "      <td>...</td>\n",
       "      <td>18.980</td>\n",
       "      <td>34.12</td>\n",
       "      <td>126.70</td>\n",
       "      <td>1124.0</td>\n",
       "      <td>0.11390</td>\n",
       "      <td>0.30940</td>\n",
       "      <td>0.3403</td>\n",
       "      <td>0.1418</td>\n",
       "      <td>0.2218</td>\n",
       "      <td>0.07820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>20.60</td>\n",
       "      <td>29.33</td>\n",
       "      <td>140.10</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>0.11780</td>\n",
       "      <td>0.27700</td>\n",
       "      <td>0.35140</td>\n",
       "      <td>0.15200</td>\n",
       "      <td>0.2397</td>\n",
       "      <td>0.07016</td>\n",
       "      <td>...</td>\n",
       "      <td>25.740</td>\n",
       "      <td>39.42</td>\n",
       "      <td>184.60</td>\n",
       "      <td>1821.0</td>\n",
       "      <td>0.16500</td>\n",
       "      <td>0.86810</td>\n",
       "      <td>0.9387</td>\n",
       "      <td>0.2650</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.12400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>7.76</td>\n",
       "      <td>24.54</td>\n",
       "      <td>47.92</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.05263</td>\n",
       "      <td>0.04362</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.1587</td>\n",
       "      <td>0.05884</td>\n",
       "      <td>...</td>\n",
       "      <td>9.456</td>\n",
       "      <td>30.37</td>\n",
       "      <td>59.16</td>\n",
       "      <td>268.6</td>\n",
       "      <td>0.08996</td>\n",
       "      <td>0.06444</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2871</td>\n",
       "      <td>0.07039</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0          17.99         10.38          122.80     1001.0          0.11840   \n",
       "1          20.57         17.77          132.90     1326.0          0.08474   \n",
       "2          19.69         21.25          130.00     1203.0          0.10960   \n",
       "3          11.42         20.38           77.58      386.1          0.14250   \n",
       "4          20.29         14.34          135.10     1297.0          0.10030   \n",
       "..           ...           ...             ...        ...              ...   \n",
       "564        21.56         22.39          142.00     1479.0          0.11100   \n",
       "565        20.13         28.25          131.20     1261.0          0.09780   \n",
       "566        16.60         28.08          108.30      858.1          0.08455   \n",
       "567        20.60         29.33          140.10     1265.0          0.11780   \n",
       "568         7.76         24.54           47.92      181.0          0.05263   \n",
       "\n",
       "     mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0             0.27760         0.30010              0.14710         0.2419   \n",
       "1             0.07864         0.08690              0.07017         0.1812   \n",
       "2             0.15990         0.19740              0.12790         0.2069   \n",
       "3             0.28390         0.24140              0.10520         0.2597   \n",
       "4             0.13280         0.19800              0.10430         0.1809   \n",
       "..                ...             ...                  ...            ...   \n",
       "564           0.11590         0.24390              0.13890         0.1726   \n",
       "565           0.10340         0.14400              0.09791         0.1752   \n",
       "566           0.10230         0.09251              0.05302         0.1590   \n",
       "567           0.27700         0.35140              0.15200         0.2397   \n",
       "568           0.04362         0.00000              0.00000         0.1587   \n",
       "\n",
       "     mean fractal dimension  ...  worst radius  worst texture  \\\n",
       "0                   0.07871  ...        25.380          17.33   \n",
       "1                   0.05667  ...        24.990          23.41   \n",
       "2                   0.05999  ...        23.570          25.53   \n",
       "3                   0.09744  ...        14.910          26.50   \n",
       "4                   0.05883  ...        22.540          16.67   \n",
       "..                      ...  ...           ...            ...   \n",
       "564                 0.05623  ...        25.450          26.40   \n",
       "565                 0.05533  ...        23.690          38.25   \n",
       "566                 0.05648  ...        18.980          34.12   \n",
       "567                 0.07016  ...        25.740          39.42   \n",
       "568                 0.05884  ...         9.456          30.37   \n",
       "\n",
       "     worst perimeter  worst area  worst smoothness  worst compactness  \\\n",
       "0             184.60      2019.0           0.16220            0.66560   \n",
       "1             158.80      1956.0           0.12380            0.18660   \n",
       "2             152.50      1709.0           0.14440            0.42450   \n",
       "3              98.87       567.7           0.20980            0.86630   \n",
       "4             152.20      1575.0           0.13740            0.20500   \n",
       "..               ...         ...               ...                ...   \n",
       "564           166.10      2027.0           0.14100            0.21130   \n",
       "565           155.00      1731.0           0.11660            0.19220   \n",
       "566           126.70      1124.0           0.11390            0.30940   \n",
       "567           184.60      1821.0           0.16500            0.86810   \n",
       "568            59.16       268.6           0.08996            0.06444   \n",
       "\n",
       "     worst concavity  worst concave points  worst symmetry  \\\n",
       "0             0.7119                0.2654          0.4601   \n",
       "1             0.2416                0.1860          0.2750   \n",
       "2             0.4504                0.2430          0.3613   \n",
       "3             0.6869                0.2575          0.6638   \n",
       "4             0.4000                0.1625          0.2364   \n",
       "..               ...                   ...             ...   \n",
       "564           0.4107                0.2216          0.2060   \n",
       "565           0.3215                0.1628          0.2572   \n",
       "566           0.3403                0.1418          0.2218   \n",
       "567           0.9387                0.2650          0.4087   \n",
       "568           0.0000                0.0000          0.2871   \n",
       "\n",
       "     worst fractal dimension  \n",
       "0                    0.11890  \n",
       "1                    0.08902  \n",
       "2                    0.08758  \n",
       "3                    0.17300  \n",
       "4                    0.07678  \n",
       "..                       ...  \n",
       "564                  0.07115  \n",
       "565                  0.06637  \n",
       "566                  0.07820  \n",
       "567                  0.12400  \n",
       "568                  0.07039  \n",
       "\n",
       "[569 rows x 30 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancer_df = pd.DataFrame(data = X, columns = cancer.feature_names)\n",
    "cancer_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "forced-forum",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.799e+01, 1.038e+01, 1.228e+02, 1.001e+03, 1.184e-01, 2.776e-01,\n",
       "       3.001e-01, 1.471e-01, 2.419e-01, 7.871e-02, 1.095e+00, 9.053e-01,\n",
       "       8.589e+00, 1.534e+02, 6.399e-03, 4.904e-02, 5.373e-02, 1.587e-02,\n",
       "       3.003e-02, 6.193e-03, 2.538e+01, 1.733e+01, 1.846e+02, 2.019e+03,\n",
       "       1.622e-01, 6.656e-01, 7.119e-01, 2.654e-01, 4.601e-01, 1.189e-01])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 샘플로 1개의 데이터 확인\n",
    "X[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amended-illness",
   "metadata": {},
   "source": [
    "## (4) train, test 데이터 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "supported-amsterdam",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋 나누기 - train/test(8:2)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    y,\n",
    "                                                    test_size = 0.2,\n",
    "                                                    random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "subject-office",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(455, 30)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "exact-ecuador",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(114, 30)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "olive-equation",
   "metadata": {},
   "source": [
    "## (5) 다양한 모델로 학습시켜보기 및 평가"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hired-permit",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "aquatic-thesis",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.93      0.93        43\n",
      "           1       0.96      0.96      0.96        71\n",
      "\n",
      "    accuracy                           0.95       114\n",
      "   macro avg       0.94      0.94      0.94       114\n",
      "weighted avg       0.95      0.95      0.95       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "decision_tree = DecisionTreeClassifier(random_state = 32)\n",
    "\n",
    "\n",
    "# 모델 학습\n",
    "decision_tree.fit(X_train, y_train)\n",
    "\n",
    "# 모델 예측\n",
    "pred_train = decision_tree.predict(X_train)\n",
    "pred_test = decision_tree.predict(X_test)\n",
    "\n",
    "# 평가\n",
    "print(classification_report(y_test, pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "located-complexity",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train 정확도: 1.0\n",
      "Test 정확도: 0.9473684210526315\n"
     ]
    }
   ],
   "source": [
    "# 정확도\n",
    "print(\"Train 정확도:\", accuracy_score(y_train, pred_train))\n",
    "print(\"Test 정확도:\", accuracy_score(y_test, pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "turkish-house",
   "metadata": {},
   "source": [
    "### Grid Search - 하이퍼 파라미터 튜닝"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "pleased-yacht",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 반복문 사용\n",
    "depth_list = range(1, 30)\n",
    "\n",
    "# 각각의 max_depth에  따른 train/test 정확도 저장할 리스트\n",
    "train_acc_list = []\n",
    "test_acc_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "stunning-environment",
   "metadata": {},
   "outputs": [],
   "source": [
    "for depth in depth_list:\n",
    "    decision_tree = DecisionTreeClassifier(max_depth = depth, random_state = 32)\n",
    "    decision_tree.fit(X_train, y_train)\n",
    "    \n",
    "    pred_train = decision_tree.predict(X_train)\n",
    "    pred_test = decision_tree.predict(X_test)\n",
    "    \n",
    "    train_acc_list.append(accuracy_score(y_train, pred_train))\n",
    "    test_acc_list.append(accuracy_score(y_test, pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "according-preparation",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_depth</th>\n",
       "      <th>Train</th>\n",
       "      <th>Test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.920879</td>\n",
       "      <td>0.894737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.929670</td>\n",
       "      <td>0.929825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.978022</td>\n",
       "      <td>0.938596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.995604</td>\n",
       "      <td>0.938596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.995604</td>\n",
       "      <td>0.947368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.997802</td>\n",
       "      <td>0.947368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.947368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.947368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.947368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.947368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.947368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.947368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.947368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.947368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.947368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.947368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.947368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.947368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.947368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.947368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.947368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.947368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.947368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.947368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.947368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.947368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.947368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.947368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.947368</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    max_depth     Train      Test\n",
       "0           1  0.920879  0.894737\n",
       "1           2  0.929670  0.929825\n",
       "2           3  0.978022  0.938596\n",
       "3           4  0.995604  0.938596\n",
       "4           5  0.995604  0.947368\n",
       "5           6  0.997802  0.947368\n",
       "6           7  1.000000  0.947368\n",
       "7           8  1.000000  0.947368\n",
       "8           9  1.000000  0.947368\n",
       "9          10  1.000000  0.947368\n",
       "10         11  1.000000  0.947368\n",
       "11         12  1.000000  0.947368\n",
       "12         13  1.000000  0.947368\n",
       "13         14  1.000000  0.947368\n",
       "14         15  1.000000  0.947368\n",
       "15         16  1.000000  0.947368\n",
       "16         17  1.000000  0.947368\n",
       "17         18  1.000000  0.947368\n",
       "18         19  1.000000  0.947368\n",
       "19         20  1.000000  0.947368\n",
       "20         21  1.000000  0.947368\n",
       "21         22  1.000000  0.947368\n",
       "22         23  1.000000  0.947368\n",
       "23         24  1.000000  0.947368\n",
       "24         25  1.000000  0.947368\n",
       "25         26  1.000000  0.947368\n",
       "26         27  1.000000  0.947368\n",
       "27         28  1.000000  0.947368\n",
       "28         29  1.000000  0.947368"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = pd.DataFrame(dict(max_depth = depth_list,\n",
    "                          Train = train_acc_list,\n",
    "                          Test = test_acc_list))\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bizarre-tunisia",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 그래프 그리기\n",
    "\n",
    "plt.figure(figsize=(7,7))\n",
    "plt.plot(depth_list, train_acc_list, label = 'Train acc')\n",
    "plt.plot(depth_list, test_acc_list, label = 'Test acc')\n",
    "plt.xlabel(\"max depth\")\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "played-alfred",
   "metadata": {},
   "source": [
    "#### RandomizedSearchCV\n",
    "- 주요 매개변수\n",
    "    - estimator: 모델객체 지정\n",
    "    - param_distributions : 하이퍼파라미터 목록을 dictionary로 전달 '파라미터명':[파라미터값 list] 형식\n",
    "    - n_iter : 파라미터 검색 횟수\n",
    "    - scoring: 평가 지표\n",
    "    - cv : 교차검증시 fold 개수. \n",
    "    - n_jobs : 사용할 CPU 코어 개수 (None:1(기본값), -1: 모든 코어 다 사용)\n",
    "- 메소드\n",
    "    - fit(X, y) : 학습\n",
    "    - predict(X): 제일 좋은 성능을 낸 모델로 predict()\n",
    "    - predict_proba(X): 제일 좋은 성능을 낸 모델로 predict_proba() 호출\n",
    "- 결과 조회 변수\n",
    "    - cv_results_ : 파라미터 조합별 결과 조회\n",
    "    - best_params_ : 가장 좋은 성능을 낸 parameter 조합 조회\n",
    "    - best_estimator_ : 가장 좋은 성능을 낸 모델 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "compound-presence",
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_tree = DecisionTreeClassifier()\n",
    "\n",
    "# 360개의 조합\n",
    "param_grid = {\n",
    "    'max_depth': range(1, 21),  # 20\n",
    "    'max_leaf_nodes': range(2, 11),  # 9\n",
    "    'criterion': ['gini', 'entropy'],  # 2\n",
    "    'random_state': [1, 32]\n",
    "}\n",
    "n_iter = 50  # 확인할 조합의 개수. default: 10개\n",
    "randomized_search = RandomizedSearchCV(decision_tree,\n",
    "                                      param_distributions = param_grid,\n",
    "                                      n_iter = n_iter,\n",
    "                                      scoring = \"accuracy\",\n",
    "                                      cv = 3,\n",
    "                                      n_jobs = -1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "heavy-gabriel",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, estimator=DecisionTreeClassifier(), n_iter=50,\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={'criterion': ['gini', 'entropy'],\n",
       "                                        'max_depth': range(1, 21),\n",
       "                                        'max_leaf_nodes': range(2, 11),\n",
       "                                        'random_state': [1, 32]},\n",
       "                   scoring='accuracy')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "randomized_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "attached-rating",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 15)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(randomized_search.cv_results_)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "assured-customer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_random_state</th>\n",
       "      <th>param_max_leaf_nodes</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_criterion</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.003168</td>\n",
       "      <td>0.000108</td>\n",
       "      <td>0.000446</td>\n",
       "      <td>1.225687e-05</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>gini</td>\n",
       "      <td>{'random_state': 1, 'max_leaf_nodes': 5, 'max_...</td>\n",
       "      <td>0.934211</td>\n",
       "      <td>0.921053</td>\n",
       "      <td>0.920530</td>\n",
       "      <td>0.925264</td>\n",
       "      <td>0.006330</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.006135</td>\n",
       "      <td>0.000526</td>\n",
       "      <td>0.000505</td>\n",
       "      <td>6.241560e-05</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>19</td>\n",
       "      <td>entropy</td>\n",
       "      <td>{'random_state': 1, 'max_leaf_nodes': 9, 'max_...</td>\n",
       "      <td>0.940789</td>\n",
       "      <td>0.921053</td>\n",
       "      <td>0.907285</td>\n",
       "      <td>0.923042</td>\n",
       "      <td>0.013750</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.005570</td>\n",
       "      <td>0.000511</td>\n",
       "      <td>0.000371</td>\n",
       "      <td>1.586633e-05</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>entropy</td>\n",
       "      <td>{'random_state': 1, 'max_leaf_nodes': 6, 'max_...</td>\n",
       "      <td>0.934211</td>\n",
       "      <td>0.927632</td>\n",
       "      <td>0.927152</td>\n",
       "      <td>0.929665</td>\n",
       "      <td>0.003220</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.003138</td>\n",
       "      <td>0.000238</td>\n",
       "      <td>0.000355</td>\n",
       "      <td>3.051344e-05</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>gini</td>\n",
       "      <td>{'random_state': 1, 'max_leaf_nodes': 6, 'max_...</td>\n",
       "      <td>0.934211</td>\n",
       "      <td>0.914474</td>\n",
       "      <td>0.920530</td>\n",
       "      <td>0.923071</td>\n",
       "      <td>0.008256</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.002118</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000333</td>\n",
       "      <td>4.199297e-06</td>\n",
       "      <td>32</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>gini</td>\n",
       "      <td>{'random_state': 32, 'max_leaf_nodes': 4, 'max...</td>\n",
       "      <td>0.940789</td>\n",
       "      <td>0.907895</td>\n",
       "      <td>0.933775</td>\n",
       "      <td>0.927486</td>\n",
       "      <td>0.014146</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.002651</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.000349</td>\n",
       "      <td>1.828463e-05</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>gini</td>\n",
       "      <td>{'random_state': 32, 'max_leaf_nodes': 3, 'max...</td>\n",
       "      <td>0.940789</td>\n",
       "      <td>0.888158</td>\n",
       "      <td>0.933775</td>\n",
       "      <td>0.920907</td>\n",
       "      <td>0.023334</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.005772</td>\n",
       "      <td>0.000589</td>\n",
       "      <td>0.000348</td>\n",
       "      <td>2.060387e-05</td>\n",
       "      <td>32</td>\n",
       "      <td>10</td>\n",
       "      <td>16</td>\n",
       "      <td>entropy</td>\n",
       "      <td>{'random_state': 32, 'max_leaf_nodes': 10, 'ma...</td>\n",
       "      <td>0.940789</td>\n",
       "      <td>0.921053</td>\n",
       "      <td>0.900662</td>\n",
       "      <td>0.920835</td>\n",
       "      <td>0.016383</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.002219</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000324</td>\n",
       "      <td>8.823277e-06</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>entropy</td>\n",
       "      <td>{'random_state': 1, 'max_leaf_nodes': 8, 'max_...</td>\n",
       "      <td>0.901316</td>\n",
       "      <td>0.901316</td>\n",
       "      <td>0.867550</td>\n",
       "      <td>0.890060</td>\n",
       "      <td>0.015918</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.002600</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.000344</td>\n",
       "      <td>9.584967e-06</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>gini</td>\n",
       "      <td>{'random_state': 32, 'max_leaf_nodes': 3, 'max...</td>\n",
       "      <td>0.940789</td>\n",
       "      <td>0.888158</td>\n",
       "      <td>0.933775</td>\n",
       "      <td>0.920907</td>\n",
       "      <td>0.023334</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.002916</td>\n",
       "      <td>0.000142</td>\n",
       "      <td>0.000338</td>\n",
       "      <td>8.591895e-06</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>gini</td>\n",
       "      <td>{'random_state': 1, 'max_leaf_nodes': 5, 'max_...</td>\n",
       "      <td>0.934211</td>\n",
       "      <td>0.921053</td>\n",
       "      <td>0.920530</td>\n",
       "      <td>0.925264</td>\n",
       "      <td>0.006330</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.005280</td>\n",
       "      <td>0.000530</td>\n",
       "      <td>0.000346</td>\n",
       "      <td>1.192146e-05</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>entropy</td>\n",
       "      <td>{'random_state': 1, 'max_leaf_nodes': 4, 'max_...</td>\n",
       "      <td>0.940789</td>\n",
       "      <td>0.888158</td>\n",
       "      <td>0.927152</td>\n",
       "      <td>0.918700</td>\n",
       "      <td>0.022303</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.005471</td>\n",
       "      <td>0.000519</td>\n",
       "      <td>0.000355</td>\n",
       "      <td>2.773113e-05</td>\n",
       "      <td>32</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>entropy</td>\n",
       "      <td>{'random_state': 32, 'max_leaf_nodes': 5, 'max...</td>\n",
       "      <td>0.940789</td>\n",
       "      <td>0.914474</td>\n",
       "      <td>0.927152</td>\n",
       "      <td>0.927472</td>\n",
       "      <td>0.010746</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.002832</td>\n",
       "      <td>0.000186</td>\n",
       "      <td>0.000324</td>\n",
       "      <td>7.811822e-06</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>gini</td>\n",
       "      <td>{'random_state': 1, 'max_leaf_nodes': 4, 'max_...</td>\n",
       "      <td>0.934211</td>\n",
       "      <td>0.907895</td>\n",
       "      <td>0.933775</td>\n",
       "      <td>0.925293</td>\n",
       "      <td>0.012304</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.003064</td>\n",
       "      <td>0.000166</td>\n",
       "      <td>0.000348</td>\n",
       "      <td>2.827715e-06</td>\n",
       "      <td>32</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>gini</td>\n",
       "      <td>{'random_state': 32, 'max_leaf_nodes': 6, 'max...</td>\n",
       "      <td>0.934211</td>\n",
       "      <td>0.921053</td>\n",
       "      <td>0.920530</td>\n",
       "      <td>0.925264</td>\n",
       "      <td>0.006330</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.002918</td>\n",
       "      <td>0.000141</td>\n",
       "      <td>0.000342</td>\n",
       "      <td>8.935662e-06</td>\n",
       "      <td>32</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>gini</td>\n",
       "      <td>{'random_state': 32, 'max_leaf_nodes': 5, 'max...</td>\n",
       "      <td>0.934211</td>\n",
       "      <td>0.921053</td>\n",
       "      <td>0.920530</td>\n",
       "      <td>0.925264</td>\n",
       "      <td>0.006330</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.002119</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000339</td>\n",
       "      <td>3.796441e-06</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>gini</td>\n",
       "      <td>{'random_state': 1, 'max_leaf_nodes': 2, 'max_...</td>\n",
       "      <td>0.901316</td>\n",
       "      <td>0.901316</td>\n",
       "      <td>0.867550</td>\n",
       "      <td>0.890060</td>\n",
       "      <td>0.015918</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.003740</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>0.000342</td>\n",
       "      <td>1.431085e-05</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>entropy</td>\n",
       "      <td>{'random_state': 1, 'max_leaf_nodes': 2, 'max_...</td>\n",
       "      <td>0.901316</td>\n",
       "      <td>0.901316</td>\n",
       "      <td>0.867550</td>\n",
       "      <td>0.890060</td>\n",
       "      <td>0.015918</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.003136</td>\n",
       "      <td>0.000170</td>\n",
       "      <td>0.000356</td>\n",
       "      <td>2.092688e-05</td>\n",
       "      <td>32</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>gini</td>\n",
       "      <td>{'random_state': 32, 'max_leaf_nodes': 6, 'max...</td>\n",
       "      <td>0.934211</td>\n",
       "      <td>0.921053</td>\n",
       "      <td>0.920530</td>\n",
       "      <td>0.925264</td>\n",
       "      <td>0.006330</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.003483</td>\n",
       "      <td>0.000085</td>\n",
       "      <td>0.000355</td>\n",
       "      <td>2.823245e-06</td>\n",
       "      <td>32</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>gini</td>\n",
       "      <td>{'random_state': 32, 'max_leaf_nodes': 7, 'max...</td>\n",
       "      <td>0.927632</td>\n",
       "      <td>0.921053</td>\n",
       "      <td>0.913907</td>\n",
       "      <td>0.920864</td>\n",
       "      <td>0.005605</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.002129</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.000337</td>\n",
       "      <td>1.643686e-05</td>\n",
       "      <td>32</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>gini</td>\n",
       "      <td>{'random_state': 32, 'max_leaf_nodes': 2, 'max...</td>\n",
       "      <td>0.901316</td>\n",
       "      <td>0.901316</td>\n",
       "      <td>0.867550</td>\n",
       "      <td>0.890060</td>\n",
       "      <td>0.015918</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.003607</td>\n",
       "      <td>0.000261</td>\n",
       "      <td>0.000343</td>\n",
       "      <td>8.485379e-07</td>\n",
       "      <td>32</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>gini</td>\n",
       "      <td>{'random_state': 32, 'max_leaf_nodes': 9, 'max...</td>\n",
       "      <td>0.934211</td>\n",
       "      <td>0.914474</td>\n",
       "      <td>0.913907</td>\n",
       "      <td>0.920864</td>\n",
       "      <td>0.009440</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.003626</td>\n",
       "      <td>0.000286</td>\n",
       "      <td>0.000341</td>\n",
       "      <td>1.170654e-05</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>gini</td>\n",
       "      <td>{'random_state': 1, 'max_leaf_nodes': 10, 'max...</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.927632</td>\n",
       "      <td>0.913907</td>\n",
       "      <td>0.929636</td>\n",
       "      <td>0.013734</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.002892</td>\n",
       "      <td>0.000258</td>\n",
       "      <td>0.000363</td>\n",
       "      <td>2.173172e-05</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>gini</td>\n",
       "      <td>{'random_state': 1, 'max_leaf_nodes': 4, 'max_...</td>\n",
       "      <td>0.934211</td>\n",
       "      <td>0.907895</td>\n",
       "      <td>0.933775</td>\n",
       "      <td>0.925293</td>\n",
       "      <td>0.012304</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.005835</td>\n",
       "      <td>0.000360</td>\n",
       "      <td>0.000360</td>\n",
       "      <td>6.924636e-06</td>\n",
       "      <td>32</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>entropy</td>\n",
       "      <td>{'random_state': 32, 'max_leaf_nodes': 8, 'max...</td>\n",
       "      <td>0.927632</td>\n",
       "      <td>0.927632</td>\n",
       "      <td>0.933775</td>\n",
       "      <td>0.929679</td>\n",
       "      <td>0.002896</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.002918</td>\n",
       "      <td>0.000187</td>\n",
       "      <td>0.000356</td>\n",
       "      <td>3.236019e-06</td>\n",
       "      <td>32</td>\n",
       "      <td>4</td>\n",
       "      <td>17</td>\n",
       "      <td>gini</td>\n",
       "      <td>{'random_state': 32, 'max_leaf_nodes': 4, 'max...</td>\n",
       "      <td>0.934211</td>\n",
       "      <td>0.907895</td>\n",
       "      <td>0.933775</td>\n",
       "      <td>0.925293</td>\n",
       "      <td>0.012304</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.003580</td>\n",
       "      <td>0.000224</td>\n",
       "      <td>0.000355</td>\n",
       "      <td>1.784834e-05</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>gini</td>\n",
       "      <td>{'random_state': 1, 'max_leaf_nodes': 7, 'max_...</td>\n",
       "      <td>0.927632</td>\n",
       "      <td>0.914474</td>\n",
       "      <td>0.913907</td>\n",
       "      <td>0.918671</td>\n",
       "      <td>0.006340</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.002853</td>\n",
       "      <td>0.000215</td>\n",
       "      <td>0.000334</td>\n",
       "      <td>9.320374e-06</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>18</td>\n",
       "      <td>gini</td>\n",
       "      <td>{'random_state': 1, 'max_leaf_nodes': 4, 'max_...</td>\n",
       "      <td>0.934211</td>\n",
       "      <td>0.907895</td>\n",
       "      <td>0.933775</td>\n",
       "      <td>0.925293</td>\n",
       "      <td>0.012304</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.002773</td>\n",
       "      <td>0.000101</td>\n",
       "      <td>0.000337</td>\n",
       "      <td>7.587057e-06</td>\n",
       "      <td>32</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>gini</td>\n",
       "      <td>{'random_state': 32, 'max_leaf_nodes': 9, 'max...</td>\n",
       "      <td>0.927632</td>\n",
       "      <td>0.901316</td>\n",
       "      <td>0.927152</td>\n",
       "      <td>0.918700</td>\n",
       "      <td>0.012294</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.005721</td>\n",
       "      <td>0.000659</td>\n",
       "      <td>0.000336</td>\n",
       "      <td>8.836153e-06</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>entropy</td>\n",
       "      <td>{'random_state': 1, 'max_leaf_nodes': 10, 'max...</td>\n",
       "      <td>0.940789</td>\n",
       "      <td>0.921053</td>\n",
       "      <td>0.907285</td>\n",
       "      <td>0.923042</td>\n",
       "      <td>0.013750</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.003632</td>\n",
       "      <td>0.000371</td>\n",
       "      <td>0.000345</td>\n",
       "      <td>1.857014e-06</td>\n",
       "      <td>32</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>gini</td>\n",
       "      <td>{'random_state': 32, 'max_leaf_nodes': 9, 'max...</td>\n",
       "      <td>0.934211</td>\n",
       "      <td>0.914474</td>\n",
       "      <td>0.913907</td>\n",
       "      <td>0.920864</td>\n",
       "      <td>0.009440</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.005169</td>\n",
       "      <td>0.000372</td>\n",
       "      <td>0.000332</td>\n",
       "      <td>6.457384e-06</td>\n",
       "      <td>32</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>entropy</td>\n",
       "      <td>{'random_state': 32, 'max_leaf_nodes': 4, 'max...</td>\n",
       "      <td>0.940789</td>\n",
       "      <td>0.888158</td>\n",
       "      <td>0.927152</td>\n",
       "      <td>0.918700</td>\n",
       "      <td>0.022303</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.005698</td>\n",
       "      <td>0.000551</td>\n",
       "      <td>0.000335</td>\n",
       "      <td>1.165247e-05</td>\n",
       "      <td>32</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "      <td>entropy</td>\n",
       "      <td>{'random_state': 32, 'max_leaf_nodes': 10, 'ma...</td>\n",
       "      <td>0.940789</td>\n",
       "      <td>0.921053</td>\n",
       "      <td>0.900662</td>\n",
       "      <td>0.920835</td>\n",
       "      <td>0.016383</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.002148</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>0.000337</td>\n",
       "      <td>1.636022e-05</td>\n",
       "      <td>32</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>gini</td>\n",
       "      <td>{'random_state': 32, 'max_leaf_nodes': 2, 'max...</td>\n",
       "      <td>0.901316</td>\n",
       "      <td>0.901316</td>\n",
       "      <td>0.867550</td>\n",
       "      <td>0.890060</td>\n",
       "      <td>0.015918</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.002200</td>\n",
       "      <td>0.000082</td>\n",
       "      <td>0.000343</td>\n",
       "      <td>3.128850e-06</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>gini</td>\n",
       "      <td>{'random_state': 1, 'max_leaf_nodes': 2, 'max_...</td>\n",
       "      <td>0.901316</td>\n",
       "      <td>0.901316</td>\n",
       "      <td>0.867550</td>\n",
       "      <td>0.890060</td>\n",
       "      <td>0.015918</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.003576</td>\n",
       "      <td>0.000242</td>\n",
       "      <td>0.000348</td>\n",
       "      <td>2.010019e-05</td>\n",
       "      <td>32</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "      <td>gini</td>\n",
       "      <td>{'random_state': 32, 'max_leaf_nodes': 10, 'ma...</td>\n",
       "      <td>0.934211</td>\n",
       "      <td>0.914474</td>\n",
       "      <td>0.913907</td>\n",
       "      <td>0.920864</td>\n",
       "      <td>0.009440</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.003415</td>\n",
       "      <td>0.000366</td>\n",
       "      <td>0.000328</td>\n",
       "      <td>5.472674e-06</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>17</td>\n",
       "      <td>gini</td>\n",
       "      <td>{'random_state': 1, 'max_leaf_nodes': 7, 'max_...</td>\n",
       "      <td>0.927632</td>\n",
       "      <td>0.914474</td>\n",
       "      <td>0.913907</td>\n",
       "      <td>0.918671</td>\n",
       "      <td>0.006340</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.002630</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>0.000335</td>\n",
       "      <td>5.804240e-06</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>gini</td>\n",
       "      <td>{'random_state': 32, 'max_leaf_nodes': 3, 'max...</td>\n",
       "      <td>0.940789</td>\n",
       "      <td>0.888158</td>\n",
       "      <td>0.933775</td>\n",
       "      <td>0.920907</td>\n",
       "      <td>0.023334</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.002246</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000335</td>\n",
       "      <td>8.036589e-06</td>\n",
       "      <td>32</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>entropy</td>\n",
       "      <td>{'random_state': 32, 'max_leaf_nodes': 6, 'max...</td>\n",
       "      <td>0.901316</td>\n",
       "      <td>0.901316</td>\n",
       "      <td>0.867550</td>\n",
       "      <td>0.890060</td>\n",
       "      <td>0.015918</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.003824</td>\n",
       "      <td>0.000122</td>\n",
       "      <td>0.000330</td>\n",
       "      <td>6.244564e-06</td>\n",
       "      <td>32</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>entropy</td>\n",
       "      <td>{'random_state': 32, 'max_leaf_nodes': 2, 'max...</td>\n",
       "      <td>0.901316</td>\n",
       "      <td>0.901316</td>\n",
       "      <td>0.867550</td>\n",
       "      <td>0.890060</td>\n",
       "      <td>0.015918</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.005606</td>\n",
       "      <td>0.000359</td>\n",
       "      <td>0.000343</td>\n",
       "      <td>1.028798e-05</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>entropy</td>\n",
       "      <td>{'random_state': 1, 'max_leaf_nodes': 5, 'max_...</td>\n",
       "      <td>0.940789</td>\n",
       "      <td>0.914474</td>\n",
       "      <td>0.927152</td>\n",
       "      <td>0.927472</td>\n",
       "      <td>0.010746</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.004582</td>\n",
       "      <td>0.003456</td>\n",
       "      <td>0.000333</td>\n",
       "      <td>5.582367e-06</td>\n",
       "      <td>32</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>gini</td>\n",
       "      <td>{'random_state': 32, 'max_leaf_nodes': 6, 'max...</td>\n",
       "      <td>0.940789</td>\n",
       "      <td>0.907895</td>\n",
       "      <td>0.933775</td>\n",
       "      <td>0.927486</td>\n",
       "      <td>0.014146</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.003368</td>\n",
       "      <td>0.000217</td>\n",
       "      <td>0.000349</td>\n",
       "      <td>1.132147e-05</td>\n",
       "      <td>32</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>gini</td>\n",
       "      <td>{'random_state': 32, 'max_leaf_nodes': 8, 'max...</td>\n",
       "      <td>0.921053</td>\n",
       "      <td>0.934211</td>\n",
       "      <td>0.913907</td>\n",
       "      <td>0.923057</td>\n",
       "      <td>0.008409</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.008276</td>\n",
       "      <td>0.003596</td>\n",
       "      <td>0.000392</td>\n",
       "      <td>1.861905e-05</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>entropy</td>\n",
       "      <td>{'random_state': 1, 'max_leaf_nodes': 8, 'max_...</td>\n",
       "      <td>0.927632</td>\n",
       "      <td>0.927632</td>\n",
       "      <td>0.933775</td>\n",
       "      <td>0.929679</td>\n",
       "      <td>0.002896</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.006027</td>\n",
       "      <td>0.000740</td>\n",
       "      <td>0.000349</td>\n",
       "      <td>1.478622e-05</td>\n",
       "      <td>32</td>\n",
       "      <td>9</td>\n",
       "      <td>19</td>\n",
       "      <td>entropy</td>\n",
       "      <td>{'random_state': 32, 'max_leaf_nodes': 9, 'max...</td>\n",
       "      <td>0.940789</td>\n",
       "      <td>0.921053</td>\n",
       "      <td>0.907285</td>\n",
       "      <td>0.923042</td>\n",
       "      <td>0.013750</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.002145</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000337</td>\n",
       "      <td>8.241454e-06</td>\n",
       "      <td>32</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>gini</td>\n",
       "      <td>{'random_state': 32, 'max_leaf_nodes': 2, 'max...</td>\n",
       "      <td>0.901316</td>\n",
       "      <td>0.901316</td>\n",
       "      <td>0.867550</td>\n",
       "      <td>0.890060</td>\n",
       "      <td>0.015918</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.003636</td>\n",
       "      <td>0.000270</td>\n",
       "      <td>0.000333</td>\n",
       "      <td>6.533230e-06</td>\n",
       "      <td>32</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>gini</td>\n",
       "      <td>{'random_state': 32, 'max_leaf_nodes': 10, 'ma...</td>\n",
       "      <td>0.934211</td>\n",
       "      <td>0.914474</td>\n",
       "      <td>0.913907</td>\n",
       "      <td>0.920864</td>\n",
       "      <td>0.009440</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.006232</td>\n",
       "      <td>0.003470</td>\n",
       "      <td>0.000341</td>\n",
       "      <td>4.000573e-06</td>\n",
       "      <td>32</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>entropy</td>\n",
       "      <td>{'random_state': 32, 'max_leaf_nodes': 2, 'max...</td>\n",
       "      <td>0.901316</td>\n",
       "      <td>0.901316</td>\n",
       "      <td>0.867550</td>\n",
       "      <td>0.890060</td>\n",
       "      <td>0.015918</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.005496</td>\n",
       "      <td>0.000549</td>\n",
       "      <td>0.000345</td>\n",
       "      <td>3.570092e-06</td>\n",
       "      <td>32</td>\n",
       "      <td>6</td>\n",
       "      <td>16</td>\n",
       "      <td>entropy</td>\n",
       "      <td>{'random_state': 32, 'max_leaf_nodes': 6, 'max...</td>\n",
       "      <td>0.934211</td>\n",
       "      <td>0.927632</td>\n",
       "      <td>0.927152</td>\n",
       "      <td>0.929665</td>\n",
       "      <td>0.003220</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.003625</td>\n",
       "      <td>0.000257</td>\n",
       "      <td>0.000342</td>\n",
       "      <td>9.155605e-06</td>\n",
       "      <td>32</td>\n",
       "      <td>10</td>\n",
       "      <td>19</td>\n",
       "      <td>gini</td>\n",
       "      <td>{'random_state': 32, 'max_leaf_nodes': 10, 'ma...</td>\n",
       "      <td>0.934211</td>\n",
       "      <td>0.914474</td>\n",
       "      <td>0.913907</td>\n",
       "      <td>0.920864</td>\n",
       "      <td>0.009440</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.005452</td>\n",
       "      <td>0.000586</td>\n",
       "      <td>0.000341</td>\n",
       "      <td>9.043858e-06</td>\n",
       "      <td>32</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>entropy</td>\n",
       "      <td>{'random_state': 32, 'max_leaf_nodes': 6, 'max...</td>\n",
       "      <td>0.934211</td>\n",
       "      <td>0.927632</td>\n",
       "      <td>0.927152</td>\n",
       "      <td>0.929665</td>\n",
       "      <td>0.003220</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0        0.003168      0.000108         0.000446    1.225687e-05   \n",
       "1        0.006135      0.000526         0.000505    6.241560e-05   \n",
       "2        0.005570      0.000511         0.000371    1.586633e-05   \n",
       "3        0.003138      0.000238         0.000355    3.051344e-05   \n",
       "4        0.002118      0.000011         0.000333    4.199297e-06   \n",
       "5        0.002651      0.000029         0.000349    1.828463e-05   \n",
       "6        0.005772      0.000589         0.000348    2.060387e-05   \n",
       "7        0.002219      0.000026         0.000324    8.823277e-06   \n",
       "8        0.002600      0.000034         0.000344    9.584967e-06   \n",
       "9        0.002916      0.000142         0.000338    8.591895e-06   \n",
       "10       0.005280      0.000530         0.000346    1.192146e-05   \n",
       "11       0.005471      0.000519         0.000355    2.773113e-05   \n",
       "12       0.002832      0.000186         0.000324    7.811822e-06   \n",
       "13       0.003064      0.000166         0.000348    2.827715e-06   \n",
       "14       0.002918      0.000141         0.000342    8.935662e-06   \n",
       "15       0.002119      0.000004         0.000339    3.796441e-06   \n",
       "16       0.003740      0.000027         0.000342    1.431085e-05   \n",
       "17       0.003136      0.000170         0.000356    2.092688e-05   \n",
       "18       0.003483      0.000085         0.000355    2.823245e-06   \n",
       "19       0.002129      0.000020         0.000337    1.643686e-05   \n",
       "20       0.003607      0.000261         0.000343    8.485379e-07   \n",
       "21       0.003626      0.000286         0.000341    1.170654e-05   \n",
       "22       0.002892      0.000258         0.000363    2.173172e-05   \n",
       "23       0.005835      0.000360         0.000360    6.924636e-06   \n",
       "24       0.002918      0.000187         0.000356    3.236019e-06   \n",
       "25       0.003580      0.000224         0.000355    1.784834e-05   \n",
       "26       0.002853      0.000215         0.000334    9.320374e-06   \n",
       "27       0.002773      0.000101         0.000337    7.587057e-06   \n",
       "28       0.005721      0.000659         0.000336    8.836153e-06   \n",
       "29       0.003632      0.000371         0.000345    1.857014e-06   \n",
       "30       0.005169      0.000372         0.000332    6.457384e-06   \n",
       "31       0.005698      0.000551         0.000335    1.165247e-05   \n",
       "32       0.002148      0.000035         0.000337    1.636022e-05   \n",
       "33       0.002200      0.000082         0.000343    3.128850e-06   \n",
       "34       0.003576      0.000242         0.000348    2.010019e-05   \n",
       "35       0.003415      0.000366         0.000328    5.472674e-06   \n",
       "36       0.002630      0.000027         0.000335    5.804240e-06   \n",
       "37       0.002246      0.000010         0.000335    8.036589e-06   \n",
       "38       0.003824      0.000122         0.000330    6.244564e-06   \n",
       "39       0.005606      0.000359         0.000343    1.028798e-05   \n",
       "40       0.004582      0.003456         0.000333    5.582367e-06   \n",
       "41       0.003368      0.000217         0.000349    1.132147e-05   \n",
       "42       0.008276      0.003596         0.000392    1.861905e-05   \n",
       "43       0.006027      0.000740         0.000349    1.478622e-05   \n",
       "44       0.002145      0.000008         0.000337    8.241454e-06   \n",
       "45       0.003636      0.000270         0.000333    6.533230e-06   \n",
       "46       0.006232      0.003470         0.000341    4.000573e-06   \n",
       "47       0.005496      0.000549         0.000345    3.570092e-06   \n",
       "48       0.003625      0.000257         0.000342    9.155605e-06   \n",
       "49       0.005452      0.000586         0.000341    9.043858e-06   \n",
       "\n",
       "   param_random_state param_max_leaf_nodes param_max_depth param_criterion  \\\n",
       "0                   1                    5               8            gini   \n",
       "1                   1                    9              19         entropy   \n",
       "2                   1                    6               7         entropy   \n",
       "3                   1                    6              10            gini   \n",
       "4                  32                    4               2            gini   \n",
       "5                  32                    3              11            gini   \n",
       "6                  32                   10              16         entropy   \n",
       "7                   1                    8               1         entropy   \n",
       "8                  32                    3              13            gini   \n",
       "9                   1                    5              20            gini   \n",
       "10                  1                    4              13         entropy   \n",
       "11                 32                    5               9         entropy   \n",
       "12                  1                    4              13            gini   \n",
       "13                 32                    6              12            gini   \n",
       "14                 32                    5              11            gini   \n",
       "15                  1                    2               2            gini   \n",
       "16                  1                    2               8         entropy   \n",
       "17                 32                    6               8            gini   \n",
       "18                 32                    7               7            gini   \n",
       "19                 32                    2              14            gini   \n",
       "20                 32                    9              11            gini   \n",
       "21                  1                   10              11            gini   \n",
       "22                  1                    4              20            gini   \n",
       "23                 32                    8              11         entropy   \n",
       "24                 32                    4              17            gini   \n",
       "25                  1                    7               8            gini   \n",
       "26                  1                    4              18            gini   \n",
       "27                 32                    9               3            gini   \n",
       "28                  1                   10               5         entropy   \n",
       "29                 32                    9              10            gini   \n",
       "30                 32                    4              10         entropy   \n",
       "31                 32                   10              13         entropy   \n",
       "32                 32                    2               5            gini   \n",
       "33                  1                    2              16            gini   \n",
       "34                 32                   10              12            gini   \n",
       "35                  1                    7              17            gini   \n",
       "36                 32                    3               9            gini   \n",
       "37                 32                    6               1         entropy   \n",
       "38                 32                    2              16         entropy   \n",
       "39                  1                    5               6         entropy   \n",
       "40                 32                    6               2            gini   \n",
       "41                 32                    8               5            gini   \n",
       "42                  1                    8              16         entropy   \n",
       "43                 32                    9              19         entropy   \n",
       "44                 32                    2               8            gini   \n",
       "45                 32                   10               7            gini   \n",
       "46                 32                    2              14         entropy   \n",
       "47                 32                    6              16         entropy   \n",
       "48                 32                   10              19            gini   \n",
       "49                 32                    6               4         entropy   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "0   {'random_state': 1, 'max_leaf_nodes': 5, 'max_...           0.934211   \n",
       "1   {'random_state': 1, 'max_leaf_nodes': 9, 'max_...           0.940789   \n",
       "2   {'random_state': 1, 'max_leaf_nodes': 6, 'max_...           0.934211   \n",
       "3   {'random_state': 1, 'max_leaf_nodes': 6, 'max_...           0.934211   \n",
       "4   {'random_state': 32, 'max_leaf_nodes': 4, 'max...           0.940789   \n",
       "5   {'random_state': 32, 'max_leaf_nodes': 3, 'max...           0.940789   \n",
       "6   {'random_state': 32, 'max_leaf_nodes': 10, 'ma...           0.940789   \n",
       "7   {'random_state': 1, 'max_leaf_nodes': 8, 'max_...           0.901316   \n",
       "8   {'random_state': 32, 'max_leaf_nodes': 3, 'max...           0.940789   \n",
       "9   {'random_state': 1, 'max_leaf_nodes': 5, 'max_...           0.934211   \n",
       "10  {'random_state': 1, 'max_leaf_nodes': 4, 'max_...           0.940789   \n",
       "11  {'random_state': 32, 'max_leaf_nodes': 5, 'max...           0.940789   \n",
       "12  {'random_state': 1, 'max_leaf_nodes': 4, 'max_...           0.934211   \n",
       "13  {'random_state': 32, 'max_leaf_nodes': 6, 'max...           0.934211   \n",
       "14  {'random_state': 32, 'max_leaf_nodes': 5, 'max...           0.934211   \n",
       "15  {'random_state': 1, 'max_leaf_nodes': 2, 'max_...           0.901316   \n",
       "16  {'random_state': 1, 'max_leaf_nodes': 2, 'max_...           0.901316   \n",
       "17  {'random_state': 32, 'max_leaf_nodes': 6, 'max...           0.934211   \n",
       "18  {'random_state': 32, 'max_leaf_nodes': 7, 'max...           0.927632   \n",
       "19  {'random_state': 32, 'max_leaf_nodes': 2, 'max...           0.901316   \n",
       "20  {'random_state': 32, 'max_leaf_nodes': 9, 'max...           0.934211   \n",
       "21  {'random_state': 1, 'max_leaf_nodes': 10, 'max...           0.947368   \n",
       "22  {'random_state': 1, 'max_leaf_nodes': 4, 'max_...           0.934211   \n",
       "23  {'random_state': 32, 'max_leaf_nodes': 8, 'max...           0.927632   \n",
       "24  {'random_state': 32, 'max_leaf_nodes': 4, 'max...           0.934211   \n",
       "25  {'random_state': 1, 'max_leaf_nodes': 7, 'max_...           0.927632   \n",
       "26  {'random_state': 1, 'max_leaf_nodes': 4, 'max_...           0.934211   \n",
       "27  {'random_state': 32, 'max_leaf_nodes': 9, 'max...           0.927632   \n",
       "28  {'random_state': 1, 'max_leaf_nodes': 10, 'max...           0.940789   \n",
       "29  {'random_state': 32, 'max_leaf_nodes': 9, 'max...           0.934211   \n",
       "30  {'random_state': 32, 'max_leaf_nodes': 4, 'max...           0.940789   \n",
       "31  {'random_state': 32, 'max_leaf_nodes': 10, 'ma...           0.940789   \n",
       "32  {'random_state': 32, 'max_leaf_nodes': 2, 'max...           0.901316   \n",
       "33  {'random_state': 1, 'max_leaf_nodes': 2, 'max_...           0.901316   \n",
       "34  {'random_state': 32, 'max_leaf_nodes': 10, 'ma...           0.934211   \n",
       "35  {'random_state': 1, 'max_leaf_nodes': 7, 'max_...           0.927632   \n",
       "36  {'random_state': 32, 'max_leaf_nodes': 3, 'max...           0.940789   \n",
       "37  {'random_state': 32, 'max_leaf_nodes': 6, 'max...           0.901316   \n",
       "38  {'random_state': 32, 'max_leaf_nodes': 2, 'max...           0.901316   \n",
       "39  {'random_state': 1, 'max_leaf_nodes': 5, 'max_...           0.940789   \n",
       "40  {'random_state': 32, 'max_leaf_nodes': 6, 'max...           0.940789   \n",
       "41  {'random_state': 32, 'max_leaf_nodes': 8, 'max...           0.921053   \n",
       "42  {'random_state': 1, 'max_leaf_nodes': 8, 'max_...           0.927632   \n",
       "43  {'random_state': 32, 'max_leaf_nodes': 9, 'max...           0.940789   \n",
       "44  {'random_state': 32, 'max_leaf_nodes': 2, 'max...           0.901316   \n",
       "45  {'random_state': 32, 'max_leaf_nodes': 10, 'ma...           0.934211   \n",
       "46  {'random_state': 32, 'max_leaf_nodes': 2, 'max...           0.901316   \n",
       "47  {'random_state': 32, 'max_leaf_nodes': 6, 'max...           0.934211   \n",
       "48  {'random_state': 32, 'max_leaf_nodes': 10, 'ma...           0.934211   \n",
       "49  {'random_state': 32, 'max_leaf_nodes': 6, 'max...           0.934211   \n",
       "\n",
       "    split1_test_score  split2_test_score  mean_test_score  std_test_score  \\\n",
       "0            0.921053           0.920530         0.925264        0.006330   \n",
       "1            0.921053           0.907285         0.923042        0.013750   \n",
       "2            0.927632           0.927152         0.929665        0.003220   \n",
       "3            0.914474           0.920530         0.923071        0.008256   \n",
       "4            0.907895           0.933775         0.927486        0.014146   \n",
       "5            0.888158           0.933775         0.920907        0.023334   \n",
       "6            0.921053           0.900662         0.920835        0.016383   \n",
       "7            0.901316           0.867550         0.890060        0.015918   \n",
       "8            0.888158           0.933775         0.920907        0.023334   \n",
       "9            0.921053           0.920530         0.925264        0.006330   \n",
       "10           0.888158           0.927152         0.918700        0.022303   \n",
       "11           0.914474           0.927152         0.927472        0.010746   \n",
       "12           0.907895           0.933775         0.925293        0.012304   \n",
       "13           0.921053           0.920530         0.925264        0.006330   \n",
       "14           0.921053           0.920530         0.925264        0.006330   \n",
       "15           0.901316           0.867550         0.890060        0.015918   \n",
       "16           0.901316           0.867550         0.890060        0.015918   \n",
       "17           0.921053           0.920530         0.925264        0.006330   \n",
       "18           0.921053           0.913907         0.920864        0.005605   \n",
       "19           0.901316           0.867550         0.890060        0.015918   \n",
       "20           0.914474           0.913907         0.920864        0.009440   \n",
       "21           0.927632           0.913907         0.929636        0.013734   \n",
       "22           0.907895           0.933775         0.925293        0.012304   \n",
       "23           0.927632           0.933775         0.929679        0.002896   \n",
       "24           0.907895           0.933775         0.925293        0.012304   \n",
       "25           0.914474           0.913907         0.918671        0.006340   \n",
       "26           0.907895           0.933775         0.925293        0.012304   \n",
       "27           0.901316           0.927152         0.918700        0.012294   \n",
       "28           0.921053           0.907285         0.923042        0.013750   \n",
       "29           0.914474           0.913907         0.920864        0.009440   \n",
       "30           0.888158           0.927152         0.918700        0.022303   \n",
       "31           0.921053           0.900662         0.920835        0.016383   \n",
       "32           0.901316           0.867550         0.890060        0.015918   \n",
       "33           0.901316           0.867550         0.890060        0.015918   \n",
       "34           0.914474           0.913907         0.920864        0.009440   \n",
       "35           0.914474           0.913907         0.918671        0.006340   \n",
       "36           0.888158           0.933775         0.920907        0.023334   \n",
       "37           0.901316           0.867550         0.890060        0.015918   \n",
       "38           0.901316           0.867550         0.890060        0.015918   \n",
       "39           0.914474           0.927152         0.927472        0.010746   \n",
       "40           0.907895           0.933775         0.927486        0.014146   \n",
       "41           0.934211           0.913907         0.923057        0.008409   \n",
       "42           0.927632           0.933775         0.929679        0.002896   \n",
       "43           0.921053           0.907285         0.923042        0.013750   \n",
       "44           0.901316           0.867550         0.890060        0.015918   \n",
       "45           0.914474           0.913907         0.920864        0.009440   \n",
       "46           0.901316           0.867550         0.890060        0.015918   \n",
       "47           0.927632           0.927152         0.929665        0.003220   \n",
       "48           0.914474           0.913907         0.920864        0.009440   \n",
       "49           0.927632           0.927152         0.929665        0.003220   \n",
       "\n",
       "    rank_test_score  \n",
       "0                15  \n",
       "1                22  \n",
       "2                 3  \n",
       "3                20  \n",
       "4                 7  \n",
       "5                25  \n",
       "6                34  \n",
       "7                41  \n",
       "8                25  \n",
       "9                15  \n",
       "10               36  \n",
       "11                9  \n",
       "12               11  \n",
       "13               15  \n",
       "14               15  \n",
       "15               41  \n",
       "16               41  \n",
       "17               15  \n",
       "18               28  \n",
       "19               41  \n",
       "20               28  \n",
       "21                6  \n",
       "22               11  \n",
       "23                1  \n",
       "24               11  \n",
       "25               39  \n",
       "26               11  \n",
       "27               36  \n",
       "28               22  \n",
       "29               28  \n",
       "30               36  \n",
       "31               34  \n",
       "32               41  \n",
       "33               41  \n",
       "34               28  \n",
       "35               39  \n",
       "36               25  \n",
       "37               41  \n",
       "38               41  \n",
       "39                9  \n",
       "40                7  \n",
       "41               21  \n",
       "42                1  \n",
       "43               22  \n",
       "44               41  \n",
       "45               28  \n",
       "46               41  \n",
       "47                3  \n",
       "48               28  \n",
       "49                3  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "behavioral-coordinate",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'random_state': 32,\n",
       " 'max_leaf_nodes': 8,\n",
       " 'max_depth': 11,\n",
       " 'criterion': 'entropy'}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "randomized_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "incorporate-chambers",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(criterion='entropy', max_depth=11, max_leaf_nodes=8,\n",
       "                       random_state=32)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "randomized_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "harmful-pakistan",
   "metadata": {},
   "source": [
    "#### 최적의 하이퍼 파라미터로 재학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "biblical-spanish",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.91      0.94        43\n",
      "           1       0.95      0.99      0.97        71\n",
      "\n",
      "    accuracy                           0.96       114\n",
      "   macro avg       0.96      0.95      0.95       114\n",
      "weighted avg       0.96      0.96      0.96       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "decision_tree = DecisionTreeClassifier(random_state = 32,\n",
    "                                       max_leaf_nodes = 8,\n",
    "                                       max_depth = 11,\n",
    "                                       criterion = 'entropy')\n",
    "# 모델 학습\n",
    "decision_tree.fit(X_train, y_train)\n",
    "\n",
    "# 모델 예측\n",
    "pred_train = decision_tree.predict(X_train)\n",
    "pred_test = decision_tree.predict(X_test)\n",
    "\n",
    "# 평가\n",
    "print(classification_report(y_test, pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "hawaiian-layout",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train 정확도: 0.9846153846153847\n",
      "Test 정확도: 0.956140350877193\n"
     ]
    }
   ],
   "source": [
    "print(\"Train 정확도:\", accuracy_score(y_train, pred_train))\n",
    "print(\"Test 정확도:\", accuracy_score(y_test, pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "killing-billion",
   "metadata": {},
   "source": [
    "#### 각 평가 지표 계산 함수\n",
    "- sklearn.metrics 모듈\n",
    "- ##### confusion_matrix(y 실제값, y 예측값)\n",
    "    - 혼돈 행렬 반환\n",
    "- ##### recall_score(y 실제값, y 예측값) \n",
    "  - Recall(재현율) 점수 반환 (Positive 중 Positive로 예측한 비율 (TPR))\n",
    "- ##### precision_score(y 실제값, y 예측값)\n",
    "  - Precision(정밀도) 점수 반환 (Positive로 예측한 것 중 Positive인 것의 비율 (PPV))\n",
    "- ##### f1_score(y 실제값, y 예측값)\n",
    "    - F1 점수 반환 (recall과 precision의 조화 평균값)\n",
    "- ##### classification_report(y 실제값, y 예측값)    \n",
    "    - 클래스 별로 recall, precision, f1 점수와 accuracy를 종합해서 보여줌"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "forced-orange",
   "metadata": {},
   "source": [
    "####   Dummy 모델 혼동행렬\n",
    "> plot_confusion_matrix함수: 버전 2.1.3에서 추가됨. 없다고 에러나는 경우 업데이트 필요 `pip install scikit-learn --upgrade`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "revolutionary-snowboard",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train confusion matrix\n",
      "[[166   3]\n",
      " [  4 282]]\n",
      "--------------------------------------------------\n",
      "Test confusion matrix\n",
      "[[39  4]\n",
      " [ 1 70]]\n"
     ]
    }
   ],
   "source": [
    "# 예측값, 실제값(Ground Truth)\n",
    "# (pred_train, y_train), (pred_test, y_test)\n",
    "# 전부 0으로 예측\n",
    "print('Train confusion matrix')\n",
    "print(confusion_matrix(y_train, pred_train))\n",
    "print(\"-\"*50)\n",
    "print('Test confusion matrix')\n",
    "print(confusion_matrix(y_test, pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "equipped-daniel",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "several-consumer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.93      0.95        43\n",
      "           1       0.96      0.99      0.97        71\n",
      "\n",
      "    accuracy                           0.96       114\n",
      "   macro avg       0.97      0.96      0.96       114\n",
      "weighted avg       0.97      0.96      0.96       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Random Forest import하기\n",
    "rf = RandomForestClassifier(random_state = 32)\n",
    "\n",
    "# 모델 학습\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# 모델 예측\n",
    "pred_train = rf.predict(X_train)\n",
    "pred_test = rf.predict(X_test)\n",
    "\n",
    "# 평가\n",
    "print(classification_report(y_test, pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fourth-history",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "virgin-partition",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.86      0.92        43\n",
      "           1       0.92      1.00      0.96        71\n",
      "\n",
      "    accuracy                           0.95       114\n",
      "   macro avg       0.96      0.93      0.94       114\n",
      "weighted avg       0.95      0.95      0.95       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SVM import하기\n",
    "svm_model = svm.SVC(random_state = 32)\n",
    "\n",
    "\n",
    "# 모델 학습\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "# 모델 예측\n",
    "y_pred = svm_model.predict(X_test)\n",
    "\n",
    "# 평가\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "detected-privilege",
   "metadata": {},
   "source": [
    "### SGD Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "increasing-oxide",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      1.00      0.95        43\n",
      "           1       1.00      0.93      0.96        71\n",
      "\n",
      "    accuracy                           0.96       114\n",
      "   macro avg       0.95      0.96      0.95       114\n",
      "weighted avg       0.96      0.96      0.96       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SGD Classifier import하기\n",
    "sgd_model = SGDClassifier(random_state = 32)\n",
    "\n",
    "\n",
    "# 모델 학습\n",
    "sgd_model.fit(X_train, y_train)\n",
    "\n",
    "# 모델 예측\n",
    "y_pred = sgd_model.predict(X_test)\n",
    "\n",
    "# 평가\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mediterranean-radius",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "nervous-following",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.91      0.94        43\n",
      "           1       0.95      0.99      0.97        71\n",
      "\n",
      "    accuracy                           0.96       114\n",
      "   macro avg       0.96      0.95      0.95       114\n",
      "weighted avg       0.96      0.96      0.96       114\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "# LogisticRegression import하기\n",
    "logistic_model = LogisticRegression(random_state = 32)\n",
    "\n",
    "\n",
    "# 모델 학습\n",
    "logistic_model.fit(X_train, y_train)\n",
    "\n",
    "# 모델 예측\n",
    "y_pred = logistic_model.predict(X_test)\n",
    "\n",
    "# 평가\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mysterious-challenge",
   "metadata": {},
   "source": [
    "## (6) 모델 평가해 보기\n",
    "- 1. 학습된 모델들의 테스트 데이터 예측 결과 어떻게 해석\n",
    "- Test_data 기준\n",
    "    - (accuracy) LogisticRegression(0.96) > RandomForest(0.96) > SGD Classifier(0.96) > DecisionTree(0.96) > SVM(0.95)\n",
    "    - (f1 score) RandomForest(0.98) > LogisticRegression(0.96) =  SGD Classifier(0.96) = RandomForest(0.96) > DecisionTree(0.96) > SVM(0.95)\n",
    "    - (Precision) LogisticRegression(0.97) = RandomForest(0.97)> SGD Classifier(0.96) > DecisionTree(0.96)\n",
    "    - (Recall) LogisticRegression(0.96) > RandomForest(0.96)> DecisionTree(0.96) = SGD Classifier(0.96) > SVM(0.95)\n",
    "    - (Specificity) RandomForest(0.96) = LogisticRegression(0.96) = SGD Classifier(0.96) = DecisionTree(0.96) > SVM(0.95)\n",
    "    \n",
    "- 2. 모델 성능 평가하는 지표로 무엇이 좋은지 평가지표 중 적절한 것 선택 및 근거\n",
    " > 3개의 항목에서LogisticRegression이 가장 높은 점수, 2개의 항목에서 RandomFroest에서 가장 높은 점수"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "outer-sight",
   "metadata": {},
   "source": [
    "### 보충. 모든 모델의 성능을 평가하는데 Classification Report 활용\n",
    "- Decision Tree는 최적의 파라미터 탐색해 재학습 진행\n",
    "- 추후, RandomForest, SVM, Logistic Regression에 대한 그리드 서치 진행해 모델 간 성능 재비교"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
